---
title: "Mistake stats"
author: "Lasse Hjorth Madsen"
date: today 
format: 
  html:
    fig-width: 7
    fig-height: 4
toc: true
toc-expand: true
editor: source
execute:
  echo: false
  warning: false
  cache: false
---

```{r setup}
library(tidyverse)
theme_set(theme_minimal())
devtools::load_all(path = "../../backgammon")
```

## Why this?

This is an exploratory analysis of a big chunk of my backgammon matches played on Backgammon Galaxy. Maybe I can spot some interesting patterns, to help better focus my learning.

```{r subset_and_clean}
cost_breaks <- c(0.02, seq(0, 0.3, 0.05), Inf) %>% sort()
cost_labels <- paste0(">", cost_breaks)[-length(cost_breaks)] %>% rev()

move_breaks <- c(0, 3, 10, 15, 20, 30, Inf) %>% rev()
move_labels <- paste0(">", move_breaks)[-1] 

df <- bgmoves %>% 
  select(file, move_no, play, turn, proper_ca, move_err, cube_err, xgid) %>% 
  group_by(file) %>% 
  mutate(next_play = lead(play, 1),
         next_cube_err = lead(cube_err, 1)) %>%
  ungroup() %>% 
  pivot_longer(cols = c(cube_err, move_err), names_to = "type", values_to = "cost") %>% 
  filter(!is.na(cost), cost < 0) %>% 
  mutate(turn = case_match(turn,  "lasse" ~ "Me", .default = "Opponent"),
         type = case_match(type, "cube_err" ~ "Cube decision", "move_err" ~ "Checker play"),
         proper_ca = str_replace_all(proper_ca, c(" double" = " (re)double",
                                                  "Double" = "(Re)double",
                                                  "redouble" = "(re)double",
                                                  "Redouble" = "(Re)double"),
                                     ),
         cost_bin = fct_rev(cut(.$cost, -cost_breaks, right = FALSE, labels = cost_labels)), 
         move_bin = fct_rev(cut(.$move_no, move_breaks, right = FALSE, labels = move_labels))
         ) 
```

# The data

Quick overview of the data I have collected:

- In total, the data set contains `r nrow(bgmoves)` decisions. Some decisions (like opening plays) appear several times; the total number of unique positions is `r bgmoves %>% distinct(xgid) %>% nrow()` 

- The positions are taken from a total of `r n_distinct(bgmoves$file)` games, from a total of `r bgmoves %>% filter(!str_detect(file, "_")) %>% distinct(file) %>% nrow()` matches.

- The number of actual errors, the positions that we will consider here, are the decisions where someone (me or my opponent) made a checker play error or cube decision error. This comes to a total of `r nrow(df)` mistakes, `r df %>% filter(turn == "Me") %>% nrow()` of which was made by me, `r df %>% filter(turn == "Opponent") %>% nrow()` by one of my `r n_distinct(bgmoves$player1)` opponents.

All positions have been analyzed by GNU Backgammon 4-ply (equivalent to eXtreme Gammon 5-ply).

The data is available on [GitHub](https://github.com/lassehjorthmadsen/backgammon), as a part of an R-package that I use as toolbox for backgammon related analyses.

## Me vs The Galaxy

First, let's just count, sum, and average all the errors, to see how they split by cube/checker play and by me/opponents. The left, middle, and right panel in the plot below shows counts, sums, and averages.

```{r}
plot_data <- df %>% 
  group_by(turn, type) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")),
         type = str_replace(type, " ", "\n"))
  
plot_data %>% 
  ggplot(aes(x = type, y = value, fill = turn)) +
  geom_col(position = "dodge") +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = NULL, y = "Value")
```

Luckily, it looks like I make fewer and smaller errors than my opponents on Backgammon Galaxy, but that is not surprising: I never use a rating filter, and therefore play opponents of all skill levels, including beginners. 

Note that the errors are not directly comparable to the performance rating, PR, that Galaxy reports. The averages shown are the average size of *errors*, not averages across all non-obvious plays like XG defines it. 

Anyway, it does look like I have plenty of room for improvement. Can we figure out what areas to focus on?

For one thing, checker play errors taken together, seem to sum to a lot more than all cube errors. This is because there are so many checker play decisions, many of them resulting in small errors. The *average* cube error is more than double of the average checker play error. 

Given that it would be hard to weed out all the checker plays that GNU BG considers small errors, it might be just as good to focus on the fewer but heavier cube errors.

Let's split by *size* of the error made, to see just how much the many small errors account for, compared to the fewer biggies.

## My errors by size

Is the total sum of errors mostly from many small errors, or a few big blunders?

```{r}
plot_data <- df %>% 
  filter(turn == "Me") %>% 
  group_by(type, cost_bin) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = cost_bin, y = value, fill = type)) +
  geom_col(position = "dodge", show.legend = FALSE) +
  facet_grid(rows = vars(metric), cols = vars(type), scales = "free_y") +
  labs(fill = NULL, x = NULL, y = "Value") 

```

The single interval of checker play errors, that contribute the most the the total cost of errors, is medium-sized on, errors between 0.05 and 0.1. And about half the checker play errors could be eliminated if I didn't make blunder at 0.1 and above. Presumably the biggest ones are the easiest to get rid of, so it makes sense to focus on blunders, as many players do.

Note, there's a significat fat tail of blunders at 0.3 and above. Many of those may have to do with oversights, mis-clicks, time-pressure, losing interest, etc. So perhaps a low haning fruit would be to just inprove focus and concentration. 

Similar for cube actions; there seem to be a good chunk of huge blunders that I should be able to get rid of. The small cube errors are maybe not worth worrying too much about. One reason is that in case of doubles, sometimes it pays to play the opponent (more on incorrect takes/passes from opponents later).

## My cube errors

Next, let's focus on my cube errors, and split by what GNU Backgammon think the proper cube action is. 

```{r}
plot_data <- df %>% 
  filter(turn == "Me", type == "Cube decision") %>% 
  group_by(proper_ca) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = proper_ca, y = value)) +
  geom_col(position = "dodge", fill = "steelblue") +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = NULL, y = "Value") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

The biggest class of my cube-related errors, comes from positions where the proper cube action is no (re)double, take (where no-redouble and no-double are lumped together). That class of cube positions are both frequent and with large, average errors. The mistake, however, can be both me doubling when I shouldn't, or me passing a no-double (which of course is always very bad).  

Let's further split by what the actual action was, so try to nail it better.

```{r}
plot_data <- df %>% 
  filter(turn == "Me", type == "Cube decision") %>% 
  group_by(play, proper_ca) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = proper_ca, y = value, fill = play)) +
  geom_col() +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = "Actual play", x = NULL, y = "Value") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

I looks like the single biggest contributer to my cube mistakes, is me doubling or re-doubling when the position isn't strong enough. (The big green bar in the middle panel.) So do I double too aggressively? Maybe a little, but on the other hand if you add together the cases where I rolled but should have doubled (the two purple bars in the middle panel) they represent also a big sum. But not quite as big as the wrong doubles. I might have to be a bit less trigger happy with the cube.

## My checker play errors

Checker play errors are a bit harder to categorize that cube errors. I'm planing on doing a algorithm to determine position type, but until then, we need to go simple. Let's look at move number, to distinguish between errors early and late in the game.


```{r}
plot_data <- df %>% 
  filter(turn == "Me", type == "Checker play") %>% 
  group_by(move_no) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = move_no, y = value)) +
  geom_col(position = "dodge", fill = "steelblue") +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = "Move number", y = "Value") 
```

Not surprisingly, most checker play errors come early in the game, since all games have a beginning, but not all games are long.

Let's bin the move number into a fewer intervals, so we can better talk about opening and later.

```{r}
plot_data <- df %>% 
  filter(turn == "Me", type == "Checker play") %>% 
  group_by(move_bin) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = move_bin, y = value)) +
  geom_col(position = "dodge", fill = "steelblue") +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = "Move number", y = "Value") 
```
Perhaps a bit surprising, the bigger part of checker play errors


## When it pays to be wrong

This is an interesting class of mistakes, is when I double positions that I shouldn't have, but are then rewarded when the opponent incorrectly passes a no-double, or takes a too-good-double. 

### Too good

```{r}
plot_data <- df %>% 
  filter(str_detect(proper_ca, "Too good"), play == "Doubles", turn == "Me")

my_avr_error <- plot_data$cost %>% mean() %>% round(2)
opp_avr_error <- plot_data$next_cube_err %>% mean() %>% round(2)
```

The data has `r nrow(plot_data)` examples of me doubling a position that is technically too good. The average error in these cases, is `r my_avr_error`. However, in `r sum(plot_data$next_play == "Accepts")` of those cases, my opponent accepted, for a huge, average error of `r plot_data %>% filter(next_play == "Accepts") %>% summarise(avr = mean(next_cube_err)) %>% pull(avr) %>% round(2)`. That makes the total, average error made by my opponents after I incorrectly double a too-good position `r opp_avr_error`. It is a very small sample, but it appears that those `r nrow(plot_data)` errors could have been profitable overall.

We could do statistical tests to better access if this result is just noise, but it is more fun to plot the data to get a feel for how to interpret it.

One way to visualize the distribution of my double-errors vs my opponent's take-errors, is to plot the estimated density distributions of errors like this:

```{r}
plot_data %>% 
  pivot_longer(c(cost, next_cube_err), names_to = "player", values_to = "cost") %>% 
  mutate(player = case_match(player, "cost" ~ "Me", "next_cube_err" ~ "Opponent")) %>%
  group_by(player) %>% 
  mutate(avr = mean(cost)) %>% 
  ungroup() %>% 
  ggplot(aes(x = cost, fill = player)) +
  geom_density(alpha = 0.5, color = NA) +
  geom_vline(aes(xintercept = avr, color = player)) +
  scale_x_continuous(breaks = c(seq(0, -1.5, -0.5), my_avr_error)) +
  labs(fill = NULL, x = "Cost of error", y = "Density",
       title =  "My costs of doubling when too good and my gains from incorrect takes",
       subtitle = "Estimated density distributions. Vertical lines show averages") +
  scale_color_discrete(guide = 'none')
```

Another way would be to plot the size of my error of doubling, against the error of my opponent. In case of a correct response, a pass, that error would just be zero. Like this:

```{r}
plot_data %>% 
  ggplot(aes(x = cost, y = next_cube_err, color = next_cube_err == 0)) +
  geom_point() +
  geom_vline(xintercept = my_avr_error, color = "grey") +
  geom_hline(yintercept = opp_avr_error, color = "grey") +
  scale_color_discrete(name = "Opponent's response", labels = c("Wrong take", "Correct pass")) +
  labs(x = "Cost of my error", y = "Cost of opponent's error",
       title =  "My costs of doubling when too good and my gains from incorrect takes",
       subtitle = "Each dot represent one pair of decisions in too-good situations. Grey lines are averages")
```

The point here is, that the bigger the no-double is, the bigger is also the potential gain from an erroneous take. While those big take-blunders may be less likely, the gain when they do happen is also bigger. The plot shows one outlier, buttom left corner, of a really big no-double that was accepted for a big gain.

It's possible that best practical strategy is to *never* play on for too-good, unless it is absolutely obvious, like when you're cruising home with a couple of opponent checkers closed out. It will most often cost something to double, because usually the opponent correctly passes, but the occasional big blunder take might outweigh that.

### Not good enough

```{r}
plot_data <- df %>% 
  filter(str_starts(proper_ca, "No"), play == "Doubles", turn == "Me")

my_avr_error <- plot_data$cost %>% mean() %>% round(2)
opp_avr_error <- plot_data$next_cube_err %>% mean() %>% round(2)
```

For these pair of decisions, the data has `r nrow(plot_data)` examples of me doubling a position that is technically not good enough. The average error in these cases, is `r my_avr_error`. In `r sum(plot_data$next_play == "Rejects")` of those cases, my opponent passed, for an average error of `r plot_data %>% filter(next_play == "Rejects") %>% summarise(avr = mean(next_cube_err)) %>% pull(avr) %>% round(2)`. That makes the total, average error made by my opponents after I incorrectly double a too-good position `r opp_avr_error`. It is still a small sample, but it appears that those `r nrow(plot_data)` errors was not justified by a subsequent opponent error.

Let's do plot similar to before. First, the estimated density distributions of errors:

```{r}
plot_data %>% 
  pivot_longer(c(cost, next_cube_err), names_to = "player", values_to = "cost") %>% 
  mutate(player = case_match(player, "cost" ~ "Me", "next_cube_err" ~ "Opponent")) %>%
  group_by(player) %>% 
  mutate(avr = mean(cost)) %>% 
  ungroup() %>% 
  ggplot(aes(x = cost, fill = player)) +
  geom_density(alpha = 0.5, color = NA) +
  geom_vline(aes(xintercept = avr, color = player)) +
  scale_x_continuous(breaks = c(seq(0, -1.5, -0.5), my_avr_error)) +
  labs(fill = NULL, x = "Cost of error", y = "Density",
       title =  "My costs of doubling when not good enough and my gains from incorrect passes",
       subtitle = "Estimated density distributions. Vertical lines show averages") +
  scale_color_discrete(guide = 'none')
```

Next, the scatter plot:

```{r}
plot_data %>% 
  ggplot(aes(x = cost, y = next_cube_err, color = next_cube_err == 0)) +
  geom_point() +
  geom_vline(xintercept = my_avr_error, color = "grey") +
  geom_hline(yintercept = opp_avr_error, color = "grey") +
  scale_color_discrete(name = "Opponent's response", labels = c("Wrong pass", "Correct take")) +
  labs(x = "Cost of my error", y = "Cost of opponent's error",
       title =  "My costs of doubling when not good enough and my gains from incorrect passes",
       subtitle = "Each dot represent one pair of decisions in not-good-enough situations. Grey lines are averages")
```



## Are higher plies worth it?

### Compare some overall results

```{r get_data}
# Create a df like bgmoves, but with all available
# levels of analysis, i.e. 0-ply, 1-ply ... 4-ply

if (file.exists("data/plies.rds")) {
  plies <- readRDS("data/plies.rds")

  } else {

  paths <- list.files(
    "..\\..\\backgammon\\data-raw\\galaxy-matches\\analyzed\\",
    full.names = TRUE) %>%
    set_names(str_extract(., "\\d.+$"))
  
  plies <- paths %>% 
    map(list.files, pattern = "*.txt", full.names = TRUE) %>% 
    map(txt2df) %>% 
    list_rbind(names_to = "ply")
  
  plies %>% saveRDS("data/plies.rds")
}
```

```{r clean_plies}
plies <- plies %>% 
  select(file, ply, move_no, play, turn, proper_ca, 
         move_err, cube_err, cube_eq, move_eq, xgid) %>% 
  pivot_longer(cols = c(cube_err, move_err), names_to = "type", values_to = "cost") %>% 
  filter(!is.na(cost), cost < 0) %>% 
  mutate(turn = case_match(turn,  "lasse" ~ "Me", .default = "Opponent"),
         type = case_match(type, "cube_err" ~ "Cube decision", "move_err" ~ "Checker play"),
         proper_ca = str_replace_all(proper_ca, c(" double" = " (re)double",
                                                  "Double" = "(Re)double",
                                                  "redouble" = "(re)double",
                                                  "Redouble" = "(Re)double"),
                                     ),
         cost_bin = fct_rev(cut(.$cost, -cost_breaks, right = FALSE, labels = cost_labels)), 
         move_bin = fct_rev(cut(.$move_no, move_breaks, right = FALSE, labels = move_labels))
         )
```


```{r}
plot_data <- plies %>% 
  group_by(turn, type, ply) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")),
         type = str_replace(type, " ", "\n"))
  
plot_data %>%
  filter(turn == "Me") %>% 
  ggplot(aes(x = type, y = value, fill = ply)) +
  geom_col(position = "dodge") +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = NULL, y = "Value")

```


```{r}
plot_data <- plies %>% 
  filter(turn == "Me") %>% 
  group_by(type, cost_bin, ply) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = cost_bin, y = value, fill = ply)) +
  geom_col(position = "dodge") +
  facet_grid(rows = vars(metric), cols = vars(type), scales = "free_y") +
  labs(fill = NULL, x = NULL, y = "Value")  +
  theme(legend.position = "bottom")
```


```{r}
plot_data <- plies %>% 
  filter(turn == "Me", type == "Cube decision") %>% 
  group_by(proper_ca, ply) %>% 
  summarise(`Count of errors` = n(), 
            `Sum of errors` = sum(cost), 
            `Average error` = `Sum of errors` / `Count of errors`, 
            .groups = "drop") %>% 
  pivot_longer(cols = c(`Count of errors`, `Sum of errors`, `Average error`), names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = c("Count of errors", "Sum of errors", "Average error")))
  
plot_data %>% 
  ggplot(aes(x = proper_ca, y = value, fill = ply)) +
  geom_col(position = "dodge") +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill= NULL, x = NULL, y = "Value") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
        legend.position = "bottom")
```

### Examples

```{r compare_positions}
# Create df to compare 3-ply and 4-ply analysis

# Subset, pivot longer, and clean
df <- plies %>% 
  select(ply, type, cost, cube_eq, move_eq, xgid) %>% 
  filter(ply %in% c("3-ply", "4-ply")) %>% 
  distinct(xgid, ply, type, .keep_all = TRUE) %>% 
  split(.$ply)

# Join 3-ply and 4-ply dfs to one
df <- df[[1]] %>% 
  left_join(df[[2]], by = c("xgid", "type"), suffix = c("_3-ply", "_4-ply"))

# Compute diffs, pick largest
df <- df %>% 
  select(-starts_with("ply_")) %>% 
  mutate(diff = `cost_3-ply` - `cost_4-ply`) %>% 
  filter(diff != 0) %>% 
  group_by(type, diff > 0) %>% 
  slice_max(order_by = abs(diff), n = 5, with_ties = FALSE) %>% 
  ungroup()

# Clean fixed width output so it renders correctly:
# Fixed width must start with 4 white spaces
df <- df %>% 
  mutate(across(starts_with("cube_eq"), 
         ~ paste0("    ", str_replace_all(.x, "\n", "\n    "))),
         across(starts_with("move_eq"), 
         ~ str_replace(.x, "\\n\\*\\s{4}", "\n    \\*"))
         )
```

```{r plot_examples}
#| layout-ncol: 1
#| results: asis

for (i in 1:nrow(df)) { 
  temp <- df %>% slice(i)
  
  cat("\n\n", "#### Position ", i, ": ", temp$type, "\n\n", sep = "")
  
  ggboard(temp$xgid) %>% print()
  
  cat("\n\n",
      "    Size of error, 3-ply: ", temp$`cost_3-ply`, "\n",
      "    Size of error, 4-ply: ", temp$`cost_4-ply`, "\n",
      "    Difference          : ", temp$diff, "\n\n", 
      sep = "")

  if (temp$type == "Cube decision") { # Cube decision
    text3 <- temp$`cube_eq_3-ply` 
    text4 <- temp$`cube_eq_4-ply` 
    cat(text3, "\n\n", text4, sep = "")
    cat("\n\n")
  } else {                            # Checker play
    text3 <- temp$`move_eq_3-ply` 
    text4 <- temp$`move_eq_4-ply` 
    cat(text3, "\n\n", text4, "\n\n", sep = "")
    cat("\n\n")
  }
}
```

