---
params:
  player_name: "lasse"
  max_examples: 20
  seed: 1970
  benchmark_name: "Llabba"

title: "Mistakes were made"
author: "Lasse Hjorth Madsen"
date: today 
format: html
toc: true
toc-expand: true
toc-depth: 4
editor: source
execute:
  echo: false
  warning: false
  cache: true
---

```{r setup}
#| cache: false
library(tidyverse)
devtools::load_all(path = "../../bglab")
theme_set(theme_minimal())
```

```{r parse}
#| cache: true
player_moves <- bgmoves |> filter(tolower(player2) == tolower(params$player_name))
```

```{r subset_and_clean}
cost_breaks <- c(0.05, 0.10, 0.20, 0.3, Inf) %>% sort()
cost_labels <- paste0(">", cost_breaks)[-length(cost_breaks)] %>% rev()

move_breaks <- c(0, 5, 15, Inf) 
move_labels <- paste0(">", move_breaks)[-length(move_breaks)] 

df_bench <- bgmoves %>%
  select(file, move_no, play, turn, proper_ca, move_err, cube_err, cube_eq, move_eq, xgid) %>% 
  pivot_longer(cols = c(cube_err, move_err), names_to = "type", values_to = "cost") %>% 
  filter(!is.na(cost), 
         cost <= -min(cost_breaks), 
         tolower(turn) %in% tolower(c(params$player_name, params$benchmark_name))) |> 
  mutate(turn = fct(tolower(turn), levels = tolower(c(params$benchmark_name, params$player_name))),
         type = case_match(type, "cube_err" ~ "Cube decision", "move_err" ~ "Checker play"),
         cost_bin = fct_rev(cut(.data$cost, -cost_breaks, right = FALSE, labels = cost_labels)), 
         move_bin = cut(.data$move_no, move_breaks, right = TRUE, labels = move_labels),
         mistake_type = case_when(
           type == "Cube decision" & play == "Rejects" & str_detect(proper_ca, "take") ~ "Wrong pass",
           type == "Cube decision" & play == "Accepts" & str_detect(proper_ca, "pass") ~ "Wrong take",
           type == "Cube decision" & play == "Doubles" & str_detect(proper_ca, "No") ~ "Wrong double",
           type == "Cube decision" & play == "Rolls" & str_detect(proper_ca, "Double|Redouble") ~ "Missed double",
           type == "Cube decision" & play == "Doubles" & str_detect(proper_ca, "Too") ~ "Wrong cash")) 

df <- df_bench |> filter(tolower(turn) == tolower(params$player_name))
```

```{r bins}
mistake_types <- unique(df$mistake_type)
mistake_types <- mistake_types[!is.na(mistake_types)]

cost_bins <- unique(df$cost_bin)
cost_bins <- cost_bins[!is.na(cost_bins)]

move_bins <- unique(df$move_bin)

set.seed(params$seed)
```

## What is this?

This is a automated report of backgammon positions where `r params$player_name` made some kind of mistake. It is intended as a learning tool, a help to identify areas where a player may benefit from study.

By design, this report displays the biggest errors made over a long series of matches, while skipping over all the brilliant plays made. Therefore, it says nothing abut the *level* of play; it only suggests what typical mistakes might look like. 

Even the best players from time to time make huge mistakes. If for no other reason because of oversight, fatigue, or mis-clicks in online games. Likely, there are some big mistakes included here: Look at them as a learning opportunity, not a wall-of-shame.

The mistakes are split into a structure like this:

  * Cube decisions
    + Wrong takes
    + Wrong passes
    + Wrong doubles 
    + Missed doubles
    + Wrong cash (when too good)
    
  * Checker plays
    + Moves 1-5 (early game)
    + Moves 6-15 (middle game)
    + Moves 16+ (end game)

All categories are then split into the same error sizes intervals like this:

  - Error > 0.05 (significant error) 
  - Error > 0.1 (big error) 
  - Error > 0.2 (huge error) 
  - Error > 0.3 (gigantic blunder, possibly an oversight or mis-click) 

## Abut the data

The report was created like this: First, I use a Python script for GNU Backgammon to analyze a collection of matches at 4- or 2-ply (doing everything at 4-ply turned out to be unfeasible). Then, my R-package [`bglab`](https://lassehjorthmadsen.github.io/bglab/index.html) contains tools to turn the GNU BG analysis files into a data frame that can be analyzed using descriptive statistics. Finally, this Quarto notebook (part of my [Backgammon Playground](https://lassehjorthmadsen.github.io/bganalyses/)) with R-code analyzes that data. 

The data are build from a set of `r n_distinct(player_moves$file)` games played by the nick `r params$player_name`. The games contains of a total of `r nrow(player_moves)` positions, from which we look at the subset of `r nrow(df)` decisions by `r params$player_name`, that GNU BG thought was in error.

In order to not create a phone book of a document, we display here only a maximum of `r params$max_examples` from each of the above mentioned categories.

## Summary statistics

A few statistical summaries might be useful. For cube handling errors, the chart below shows:

- The number of cube errors made (as a percentage)
- The sum cube errors (in percent of total)
- The average size of cube errors (normalized to money game equivalent, emg)

With all of the above split by type of error (wrong double, wrong take, etc.) and compared to a benchmark player. 

```{r cubesums}
#| fig-width: 8
metric_labels <- c("Count of errors (pct)", "Sum of errors (pct)", "Average error (emg)")

plot_data <- df_bench %>% 
  filter(type == "Cube decision") %>% 
  group_by(turn) |> 
  mutate(total_errors = n(),
         sum_errors = sum(cost)) %>%   
  group_by(turn, mistake_type) %>% 
  summarise(`Count of errors (pct)` = n() / max(total_errors) * 100, 
            `Sum of errors (pct)` = sum(cost) / max(sum_errors) * 100, 
            `Average error (emg)` = sum(cost) / n(), 
            .groups = "drop") %>% 
  pivot_longer(cols = metric_labels, names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = metric_labels),
         width = case_when(turn == tolower(params$player_name) ~ 0.8, TRUE ~ 0.4),
         alpha = case_when(turn == tolower(params$player_name) ~ 0.5, TRUE ~ 0.5))
  
plot_data %>% 
  ggplot(aes(x = mistake_type, y = value, fill = turn, width = width)) +
  geom_col(position = "identity", aes(alpha = alpha)) +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = NULL, y = NULL) +
  scale_alpha(guide = 'none') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(title = "Summary statistics for cube errors",
       subtitle = paste(params$player_name, "compared to benchmark", params$benchmark_name)
       )
```
The checker play errors are grouped by move number (counting each player's turn as a move) so we can roughly isolate opening errors and endgame errors. 

```{r checkersums}
plot_data <- df_bench %>% 
  filter(type == "Checker play") %>% 
  group_by(turn) |> 
  mutate(total_errors = n(),
         sum_errors = sum(cost)) |>  
  group_by(turn, move_bin) %>% 
  summarise(`Count of errors (pct)` = n() / max(total_errors) * 100, 
            `Sum of errors (pct)` = sum(cost) / max(sum_errors) * 100, 
            `Average error (emg)` = sum(cost) / n(), 
            .groups = "drop") %>% 
  pivot_longer(cols = metric_labels, names_to = "metric") %>% 
  mutate(metric = fct(metric, levels = metric_labels),
         width = case_when(turn == tolower(params$player_name) ~ 0.8, TRUE ~ 0.4),
         alpha = case_when(turn == tolower(params$player_name) ~ 0.5, TRUE ~ 0.5))
  
plot_data %>% 
  ggplot(aes(x = move_bin, y = value, fill = turn, width = width)) +
  geom_col(position = "identity", aes(alpha = alpha)) +
  facet_wrap(facets = vars(metric), scales = "free") +
  labs(fill = NULL, x = "Move number", y = NULL) +
  scale_alpha(guide = 'none') +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(title = "Summary statistics for checker play errors",
       subtitle = paste(params$player_name, "compared to benchmark", params$benchmark_name)
       )
```


And now, the time has finally come to show actual positions. Without further ado, here's the Big Catalog of Errors.

## Cube decisions
   
```{r cubes}
#| results: asis
for (j in mistake_types) {
  cat("\n### ", j)
  
  for (k in levels(cost_bins)) {
    cat("\n#### Error", k)
    
    temp <- df %>%
      filter(type == "Cube decision",
             mistake_type == j,
             cost_bin == k) %>%
      slice_sample(n = params$max_examples)
    
    if (nrow(temp) > 0) {
      for (i in 1:nrow(temp)) {
        cat("\n##### Position ", i)
        ggboard(temp$xgid[i]) %>% print()
        
        evaluation <- temp$cube_eq[i] %>% 
          read_lines() %>% 
          paste(rep("   ", length(.)), .) %>% 
          paste(collapse = "\n")
        
        cat("\n\n", evaluation, 
            "\n\n    ", temp$xgid[i], 
            "\n    File: ", temp$file[i], 
            "\n    Move: ", temp$move_no[i], 
            "\n\n", sep = "")
      }
    }
  }
}
```

## Checker plays

```{r checker}
#| results: asis
for (j in levels(move_bins)) {
  cat("\n### Move no. ", j)
  
  for (k in levels(cost_bins)) {
    cat("\n#### Error", k)
    
    temp <- df %>%
      filter(type == "Checker play",
             move_bin == j,
             cost_bin == k) %>%
      slice_sample(n = params$max_examples)
    
    if (nrow(temp) > 0) {
      for (i in 1:nrow(temp)) {
        cat("\n##### Position ", i)
        ggboard(temp$xgid[i]) %>% print()
        
        evaluation <- temp$move_eq[i] %>% 
          read_lines() %>% 
          str_remove_all("Cubeful ") %>% 
          paste(rep("   ", length(.)), .) %>% 
          paste(collapse = "\n")
        
        cat("\n\n", evaluation, 
            "\n\n    ", temp$xgid[i], 
            "\n    File: ", temp$file[i], 
            "\n    Move: ", temp$move_no[i], 
            "\n\n", sep = "")
      }
    }
  }
}
```